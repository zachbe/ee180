Zach Belateche and Vinh Nguyen
Hostname ee180-22z.stanford.edu

Single Threaded Optimizations
Overview
We optimized the single threaded algorithm using neon intrinsics to unroll the loops, and also refactored the code to calculate less where possible. We also compared the effects of the compiler flags -O2, -O3, and -Ofast, and chose the one that led to the the best performance. 
Vectorization Optimizations
We used intrinsics to load 8 pixels at a time and perform the grayscale on each of them. VLD3 was used to separate the channels, and then the channels were split into two 32-bit registers to do floating point arithmetic. This sped up the calculation of grayscale because each instruction operated on at least four pixels' worth of data. We also unrolled the loop to a single loop that iterated over the flattened array rather than abstracting it as a matrix. This led to fewer calculations for the indices and fewer instructions to calculate for the entire image, at the cost of the overhead of moving between different-sized registers and splitting, etc.

We sped up the sobel filter by removing the redundant x and y loops, which are calculating terms which eventually cancel when the x and y convolutions are added. Instead, for each pixel we calculate the x and y convolution simultaneously and return the total sum. This led to only 6 neighbors that contributed to the final output, so not every neighbor had to be accessed, and only one loop of data accesses were needed, which at least doubled the speed of the sobelCalc() method, independently of vectorization. For each neighbor(maintained as a pointer which incremented every iteration) a vector of 8 pixels was loaded; the convolution for 8 pixels could be calculated at once this way. 

Multi Threaded Optimizations
For this part, we have our controller thread set up the video input and slice it into two half-frames, each of which is processed by a different thread. To allow for proper convolution, each "half frame" contains one extra line of pixes above or below where it is supposed to be cut off, so the images can be cleanly joined by the controller thread after image processing has taken place. Image processing is done in between two pthread barriers, so that the non-controller thread can't start before its half of the image is ready, and the controller thread can't start combining images before the non-controller's half is processed. This meant that the image processing occurred twice as fast, at the cost of a small slowdown in pre- and post-processing due to splitting the image.

We achieved a speedup of 1.38 over the optimized, single threaded version. The factor is much less than the ideal of 2 because the threading primarily sped up the calculation of grayscale() and sobelCalc(), which together in the optimized single-threaded version accounts for around half the total runtime. After multithreading these functions account for about a third of the runtime; this corresponds to roughly doubling of the speed of these functions, if everything else is held constant. With this rough approximation we conclude the speedup of multithreading is reasonably close to ideal, assuming we cannot improve capture or display.
We achieved a total speedup of 15.54 over the unoptimized, single threaded version. 
